{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    t_web  t_uf  t_lf      e_s\n",
      "31      5     4     4  111.160\n",
      "26      3     3     6  134.970\n",
      "4       3     7     7  103.390\n",
      "14      5     7     4  108.200\n",
      "10      5     3     5  108.040\n",
      "33      5     5     5  106.160\n",
      "23      7     6     5   86.179\n",
      "32      5     5     3  124.860\n",
      "20      7     3     7   87.279\n",
      "18      6     6     4   97.607\n",
      "6       4     4     5  112.420\n",
      "13      5     6     3  121.770\n",
      "7       4     5     6  102.610\n",
      "36      6     4     6   90.704\n",
      "1       3     4     4  128.200\n",
      "16      6     4     7   88.380\n",
      "0       3     3     3  155.010\n",
      "15      6     3     6   97.780\n",
      "5       4     3     4  118.570\n",
      "11      5     4     6   97.007\n",
      "9       4     7     3  131.150\n",
      "8       4     6     7   96.970\n",
      "12      5     5     7   93.031\n",
      "37      6     6     6   88.171\n",
      " processing data\n",
      "[[0.5  0.25 0.25]\n",
      " [0.   0.   0.75]\n",
      " [0.   1.   1.  ]\n",
      " [0.5  1.   0.25]\n",
      " [0.5  0.   0.5 ]\n",
      " [0.5  0.5  0.5 ]\n",
      " [1.   0.75 0.5 ]\n",
      " [0.5  0.5  0.  ]\n",
      " [1.   0.   1.  ]\n",
      " [0.75 0.75 0.25]\n",
      " [0.25 0.25 0.5 ]\n",
      " [0.5  0.75 0.  ]\n",
      " [0.25 0.5  0.75]\n",
      " [0.75 0.25 0.75]\n",
      " [0.   0.25 0.25]\n",
      " [0.75 0.25 1.  ]\n",
      " [0.   0.   0.  ]\n",
      " [0.75 0.   0.75]\n",
      " [0.25 0.   0.25]\n",
      " [0.5  0.25 0.75]\n",
      " [0.25 1.   0.  ]\n",
      " [0.25 0.75 1.  ]\n",
      " [0.5  0.5  1.  ]\n",
      " [0.75 0.75 0.75]]\n",
      "[INFO] training model...\n",
      "Train on 24 samples, validate on 14 samples\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 1s 34ms/sample - loss: 102.3827 - val_loss: 90.1012\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 101.6682 - val_loss: 89.3164\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 100.9461 - val_loss: 88.5372\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 100.2178 - val_loss: 87.7703\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 99.4591 - val_loss: 87.0045\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 332us/sample - loss: 98.6844 - val_loss: 86.1974\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 332us/sample - loss: 97.9037 - val_loss: 85.4072\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 97.1056 - val_loss: 84.6317\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 96.3064 - val_loss: 83.8531\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 95.5321 - val_loss: 83.0730\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 335us/sample - loss: 94.7527 - val_loss: 82.2891\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 93.9941 - val_loss: 81.4791\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 93.2671 - val_loss: 80.7042\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 92.5593 - val_loss: 79.9685\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 91.8521 - val_loss: 79.2328\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 91.1455 - val_loss: 78.4967\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 90.4693 - val_loss: 77.7742\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 89.8791 - val_loss: 77.0630\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 89.2925 - val_loss: 76.3612\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 88.7033 - val_loss: 75.6766\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 88.0955 - val_loss: 74.9981\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 87.4883 - val_loss: 74.3235\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 86.8754 - val_loss: 73.6511\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 86.2607 - val_loss: 72.9807\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 85.6402 - val_loss: 72.3106\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 85.0179 - val_loss: 71.6390\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 84.3948 - val_loss: 70.9663\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 83.7708 - val_loss: 70.2808\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 83.1404 - val_loss: 69.5855\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 82.4956 - val_loss: 68.8874\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 81.8476 - val_loss: 68.1848\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 81.1806 - val_loss: 67.4802\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 80.5101 - val_loss: 66.7717\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 79.8363 - val_loss: 66.0590\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 79.1478 - val_loss: 65.3415\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 78.4551 - val_loss: 64.6205\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 77.7557 - val_loss: 63.8993\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 77.0498 - val_loss: 63.1743\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 76.3373 - val_loss: 62.4366\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 75.6068 - val_loss: 61.6857\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 74.8608 - val_loss: 60.9125\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 74.1125 - val_loss: 60.1130\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 73.3593 - val_loss: 59.2931\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 1ms/sample - loss: 72.5941 - val_loss: 58.4489\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 71.8123 - val_loss: 57.5830\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 71.0254 - val_loss: 56.6773\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 70.2389 - val_loss: 55.7583\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 1ms/sample - loss: 69.4236 - val_loss: 54.8169\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 68.5919 - val_loss: 53.9174\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 67.7810 - val_loss: 53.1146\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 67.0495 - val_loss: 52.3167\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 66.2996 - val_loss: 51.5022\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 65.5410 - val_loss: 50.6596\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 64.7781 - val_loss: 49.8212\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 64.0002 - val_loss: 48.9822\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 63.1951 - val_loss: 48.1378\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 62.3595 - val_loss: 47.2827\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 61.5199 - val_loss: 46.3857\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 60.6861 - val_loss: 45.4706\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 59.8391 - val_loss: 44.5320\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 58.9837 - val_loss: 43.5649\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 58.1164 - val_loss: 42.5613\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 57.2711 - val_loss: 41.5499\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 56.3837 - val_loss: 40.5415\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 55.4873 - val_loss: 39.5618\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 54.5805 - val_loss: 38.5924\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 53.6634 - val_loss: 37.6147\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 52.7057 - val_loss: 36.6994\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 51.7121 - val_loss: 35.9426\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 50.7197 - val_loss: 35.1801\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 667us/sample - loss: 49.7313 - val_loss: 34.4119\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 48.7340 - val_loss: 33.6381\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 47.7284 - val_loss: 32.8679\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 46.8271 - val_loss: 32.2918\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 45.9408 - val_loss: 31.7178\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 45.0770 - val_loss: 31.1508\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 44.3134 - val_loss: 30.5889\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 43.5583 - val_loss: 30.0258\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 42.8079 - val_loss: 29.4114\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 42.0614 - val_loss: 28.8005\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 1ms/sample - loss: 41.3147 - val_loss: 28.1919\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 40.5624 - val_loss: 27.5596\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 39.8217 - val_loss: 27.1255\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 39.0829 - val_loss: 26.6919\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 1ms/sample - loss: 38.3451 - val_loss: 26.2581\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 37.5905 - val_loss: 25.8220\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 667us/sample - loss: 36.8107 - val_loss: 25.4183\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 36.0389 - val_loss: 25.1676\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 35.3738 - val_loss: 25.0936\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 34.7725 - val_loss: 25.3458\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 34.1697 - val_loss: 25.9589\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 33.5712 - val_loss: 26.5541\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 33.0904 - val_loss: 27.0764\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 32.7451 - val_loss: 27.5328\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 32.4019 - val_loss: 27.9299\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 32.0607 - val_loss: 28.2736\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 31.7213 - val_loss: 28.5691\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 31.4243 - val_loss: 28.8048\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 31.1626 - val_loss: 28.9574\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 30.9058 - val_loss: 29.0382\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 30.6473 - val_loss: 29.0366\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 30.4239 - val_loss: 28.9629\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 30.1834 - val_loss: 28.8247\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 29.9234 - val_loss: 28.6292\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 29.6606 - val_loss: 28.3733\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 29.3897 - val_loss: 28.0734\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 29.1111 - val_loss: 27.7349\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 28.8262 - val_loss: 27.3636\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 28.5361 - val_loss: 26.9701\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 28.2419 - val_loss: 26.5514\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 27.9708 - val_loss: 26.1355\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 27.7028 - val_loss: 25.7222\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 27.4355 - val_loss: 25.3116\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 27.1689 - val_loss: 24.9038\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 26.9029 - val_loss: 24.4986\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 26.6377 - val_loss: 24.0962\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 26.3730 - val_loss: 23.6968\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 26.1250 - val_loss: 23.3163\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 25.8895 - val_loss: 22.9529\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 25.6549 - val_loss: 22.6086\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 25.4224 - val_loss: 22.3227\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 25.1910 - val_loss: 22.0477\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 24.9601 - val_loss: 21.7814\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 24.7306 - val_loss: 21.5230\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 24.5017 - val_loss: 21.2742\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 24.2729 - val_loss: 21.0340\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 24.0440 - val_loss: 20.8058\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 23.8152 - val_loss: 20.5868\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 999us/sample - loss: 23.5899 - val_loss: 20.3763\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 23.3643 - val_loss: 20.1734\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 23.1382 - val_loss: 19.9794\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 22.9116 - val_loss: 19.7922\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 22.6846 - val_loss: 19.6109\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 22.4572 - val_loss: 19.4351\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 22.2292 - val_loss: 19.2642\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 332us/sample - loss: 22.0007 - val_loss: 19.0980\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 331us/sample - loss: 21.7718 - val_loss: 18.9357\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 21.5428 - val_loss: 18.7741\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 21.3143 - val_loss: 18.6149\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 21.0857 - val_loss: 18.4567\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 20.8572 - val_loss: 18.2994\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 20.6283 - val_loss: 18.1431\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 20.3989 - val_loss: 17.9878\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 20.1692 - val_loss: 17.8334\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 19.9388 - val_loss: 17.6796\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 19.7075 - val_loss: 17.5265\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 19.4756 - val_loss: 17.3741\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 19.2507 - val_loss: 17.2219\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 19.0284 - val_loss: 17.0715\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 18.8061 - val_loss: 16.9229\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 18.5836 - val_loss: 16.7760\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 18.3610 - val_loss: 16.6307\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 18.1380 - val_loss: 16.4870\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 17.9132 - val_loss: 16.3430\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 17.6871 - val_loss: 16.1973\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 17.4602 - val_loss: 16.0501\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 17.2326 - val_loss: 15.9016\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 17.0295 - val_loss: 15.7352\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 16.8293 - val_loss: 15.5526\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 16.6729 - val_loss: 15.3446\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 16.5236 - val_loss: 15.1170\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 16.3680 - val_loss: 14.8698\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 335us/sample - loss: 16.2068 - val_loss: 14.6046\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 16.0407 - val_loss: 14.3235\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 15.8701 - val_loss: 14.0281\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 15.6956 - val_loss: 13.7199\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 15.5176 - val_loss: 13.4005\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 15.3365 - val_loss: 13.0710\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 15.1570 - val_loss: 12.7399\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 14.9894 - val_loss: 12.4074\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 14.8206 - val_loss: 12.0739\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 14.6508 - val_loss: 11.7395\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 14.4801 - val_loss: 11.4177\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 14.3223 - val_loss: 11.1661\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 14.1656 - val_loss: 10.9290\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 14.0052 - val_loss: 10.7051\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 331us/sample - loss: 13.8395 - val_loss: 10.4933\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 13.6687 - val_loss: 10.2925\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 13.4935 - val_loss: 10.1284\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 13.3179 - val_loss: 9.9817\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 13.1530 - val_loss: 9.8440\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 12.9872 - val_loss: 9.7161\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 12.8206 - val_loss: 9.5908\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 12.6534 - val_loss: 9.4715\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 12.4992 - val_loss: 9.3527\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 12.3741 - val_loss: 9.2341\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 12.2447 - val_loss: 9.1177\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 12.1235 - val_loss: 9.0031\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 332us/sample - loss: 12.0049 - val_loss: 8.8900\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 11.8823 - val_loss: 8.7780\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 331us/sample - loss: 11.7552 - val_loss: 8.6671\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 333us/sample - loss: 11.6238 - val_loss: 8.5739\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 11.5090 - val_loss: 8.5004\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 11.4098 - val_loss: 8.4249\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 11.3094 - val_loss: 8.3475\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 11.2187 - val_loss: 8.2633\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 11.1319 - val_loss: 8.1730\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 11.0429 - val_loss: 8.0771\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 10.9520 - val_loss: 7.9761\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 10.8599 - val_loss: 7.8723\n",
      "[[84.11387]]\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def data_value(df, train, test):\n",
    "\t# initialize the column names of the continuous data\n",
    "\tcontinuous = [\"t_web\", \"t_uf\", \"t_lf\"]\n",
    "\t# performin min-max scaling each continuous feature column to\n",
    "\t# the range [0, 1]\n",
    "\tcs = MinMaxScaler()\n",
    "\ttrainX = cs.fit_transform(train[continuous])\n",
    "\ttestX = cs.transform(test[continuous])\n",
    "\t#print(testX)\n",
    "\tprint(trainX)   \n",
    "\treturn (trainX, testX)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_mlp(dim, regress=False):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "\tmodel.add(Dense(4, activation=\"relu\"))\n",
    "\t# check to see if the regression node should be added\n",
    "\tif regress:\n",
    "\t\tmodel.add(Dense(1, activation=\"linear\"))\n",
    "\t# return our model\n",
    "\treturn model\n",
    "\n",
    "\n",
    "# To load data\n",
    "\n",
    "cols = [\"t_web\", \"t_uf\", \"t_lf\", \"e_s\"]\n",
    "df = pd.read_csv(r\"D:\\MTP\\my project\\detail.csv\", sep=\",\", header=None, names=cols)\n",
    "\n",
    "\n",
    "(train, test) = train_test_split(df, test_size=0.35, random_state=1)\n",
    "print(train)\n",
    "\n",
    "EqStress = train[\"e_s\"].max()\n",
    "trainY = train[\"e_s\"] / EqStress\n",
    "testY = test[\"e_s\"] / EqStress\n",
    "\n",
    "print(\" processing data\")\n",
    "(trainX, testX) = data_value(df, train, test)\n",
    "\n",
    "\n",
    "\n",
    "model = create_mlp(trainX.shape[1], regress=True)\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(x=trainX, y=trainY,validation_data=(testX, testY),epochs=200)\n",
    "\n",
    "\n",
    "\n",
    "# make predictions on the testing data\n",
    "preds = model.predict(testX)\n",
    "#print(preds)\n",
    "\n",
    "x_in =np.array([[1,0.5,0.5 ]])\n",
    "x_in.reshape(3,)\n",
    "y_res=model.predict(x_in)\n",
    "y_res.flatten()\n",
    "print(y_res*EqStress)\n",
    "\n",
    "\n",
    "\n",
    "diff = preds.flatten() - testY\n",
    "percentDiff = (diff / testY) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    "\n",
    "print(history.history.keys())\n",
    "#%tensorboard --logdir logs/fit\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,201)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-3-9e02cfefa239>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-9e02cfefa239>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ann_viz(model, view=True, filename=network.gv, title=MyNeural Network)\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "ann_viz(model, view=True, filename=network.gv, title=MyNeural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'F:\\anaconda\\anaconda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install ann_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['acc']\n",
    "loss_val = history.history['val_acc']\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
